{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from models.rstnet import Transformer, TransformerEncoder, TransformerDecoderLayer, ScaledDotProductAttention\n",
    "from data.tokenizers import Tokenizer\n",
    "from data.medicalDataloaders import R2DataLoader\n",
    "from models.visual_extractor import VisualExtractor\n",
    "import argparse\n",
    "import evaluation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sd = torch.load('/GPUFS/nsccgz_ywang_zfd/limengfei/RSTNet/saved_transformer_models/rstnet_250.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        self.image_dir = '../ReportGen/data/iu_xray/images/'\n",
    "        self.ann_path = '../ReportGen/data/iu_xray/annotation.json'\n",
    "\n",
    "        self.dataset_name = 'iu_xray'\n",
    "        self.max_seq_length = 60\n",
    "        self.threshold = 3\n",
    "        self.num_workers = 2\n",
    "        self.batch_size = 8\n",
    "\n",
    "        self.visual_extractor = 'resnet101'\n",
    "        self.visual_extractor_pretrained = True\n",
    "\n",
    "        self.d_model = 512\n",
    "        self.d_ff = 512\n",
    "        self.d_vf = 2048\n",
    "        self.num_heads = 8\n",
    "        self.num_layers = 3\n",
    "        self.dropout = 0.1\n",
    "        self.logit_layers = 1\n",
    "        self.bos_idx = 0\n",
    "        self.eos_idx = 0\n",
    "        self.pad_idx = 0\n",
    "        self.use_bn = 0\n",
    "        self.drop_prob_lm = 0.5\n",
    "      \n",
    "        self.img_size = 224\n",
    "        self.patch_size = 32\n",
    "        self.num_channels = 3\n",
    "        self.embedding_dim = 512\n",
    "        self.num_heads_tnt = 8\n",
    "        self.num_layers_tnt = 12\n",
    "        self.hidden_dim = 512*4\n",
    "        self.stride = 4\n",
    "        self.num_class = 761\n",
    "\n",
    "        self.sample_method = 'beam_search'\n",
    "        self.beam_size = 3\n",
    "        self.temperature = 1.0\n",
    "        self.sample_n = 1\n",
    "        self.group_size = 1\n",
    "        self.output_logsoftmax = 1\n",
    "        self.decoding_constraint = 0\n",
    "        self.block_trigrams = 1\n",
    "\n",
    "        self.n_gpu = 1\n",
    "        self.epochs = 100\n",
    "        self.save_dir = 'results/iu_xray/'\n",
    "        self.record_dir = 'records/'\n",
    "        self.save_period = 1\n",
    "        self.monitor_mode = 'max'\n",
    "        self.monitor_metric = 'BLEU_4'\n",
    "        self.early_stop = 50\n",
    "\n",
    "        self.optim = 'Adam'\n",
    "        self.lr_ed = 1e-4\n",
    "        self.weight_decay = 5e-5\n",
    "        self.amsgrad = True\n",
    "\n",
    "        self.lr_scheduler = 'StepLR'\n",
    "        self.step_size = 50\n",
    "        self.gamma = 0.1\n",
    "\n",
    "        self.seed = 9223\n",
    "        self.resume = True\n",
    "arg = args()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tokenizer = Tokenizer(arg)\n",
    "dataloader_test = R2DataLoader(arg, tokenizer, split='test', shuffle=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "device = torch.device('cuda')\n",
    "encoder = TransformerEncoder(3, 0, attention_module=ScaledDotProductAttention, attention_module_kwargs={'m': 40})\n",
    "decoder = TransformerDecoderLayer(tokenizer.get_vocab_size(), 59, 3, tokenizer.token2idx['<pad>'])\n",
    "ve = VisualExtractor(arg).to(device)\n",
    "model = Transformer(tokenizer.token2idx['<bos>'], encoder, decoder).to(device)\n",
    "model.load_state_dict(sd['tr_state_dict'])\n",
    "ve.load_state_dict(sd['ve_state_dict'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model.eval()\n",
    "gen = {}\n",
    "gts = {}\n",
    "for it, (images_id, images, captions, reports_masks) in enumerate(dataloader_test):\n",
    "    images, captions, reports_masks = images.to(device), captions.to(device), reports_masks.to(device)\n",
    "    with torch.no_grad():\n",
    "        features = ve(images)\n",
    "        out, _ = model.beam_search(features, arg.max_seq_length, tokenizer.token2idx['<eos>'], arg.beam_size, out_size=1)\n",
    "    caps_gen = tokenizer.decode_batch(out[..., :-1])\n",
    "    caps_gt = tokenizer.decode_batch(captions[..., 1:])\n",
    "    for i, (gts_i, gen_i) in enumerate(zip(caps_gt, caps_gen)):\n",
    "        # gen_i = ' '.join([k for k, g in itertools.groupby(gen_i)])\n",
    "        gen['%d_%d' % (it, i)] = [gen_i, ]\n",
    "        # gen['%d_%d' % (it, i)] = [gen_i]\n",
    "        # gts['%d_%d' % (it, i)] = gts_i\n",
    "        gts['%d_%d' % (it, i)] = [gts_i, ]\n",
    "gts = evaluation.PTBTokenizer.tokenize(gts)\n",
    "gen = evaluation.PTBTokenizer.tokenize(gen)\n",
    "scores, _ = evaluation.compute_scores(gts, gen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'java'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c66e8b7e8bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# gts['%d_%d' % (it, i)] = gts_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%d_%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgts_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPTBTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPTBTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/limengfei/RSTNet/evaluation/tokenizer.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(cls, corpus)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# tokenize sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         p_tokenizer = subprocess.Popen(cmd, cwd=path_to_jar_dirname, \\\n\u001b[0m\u001b[1;32m     48\u001b[0m                 stdout=subprocess.PIPE, stderr=open(os.devnull, 'w'))\n\u001b[1;32m     49\u001b[0m         \u001b[0mtoken_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/limengfei/Anaconda3/envs/torch15/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    856\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    859\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/limengfei/Anaconda3/envs/torch15/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'java'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(scores)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082fa2c9100d4f72183fc6a3d7367acaa09e2640f3f57a3f6d869523cd63ccb9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}